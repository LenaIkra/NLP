# –ö–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏—è –ø—Ä–∏–æ—Ä–∏—Ç–µ—Ç–æ–≤ —Å–æ–æ–±—â–µ–Ω–∏–π (Telegram-—Ç–∏–∫–µ—Ç—ã)

–ü—Ä–æ–µ–∫—Ç –≤ —Ä–∞–º–∫–∞—Ö –∫—É—Ä—Å–∞ NLP.  
–ó–∞–¥–∞—á–∞ ‚Äî –∫–ª–∞—Å—Å–∏—Ñ–∏—Ü–∏—Ä–æ–≤–∞—Ç—å —Å–æ–æ–±—â–µ–Ω–∏—è (—Ç–∏–∫–µ—Ç—ã –ø–æ–¥–¥–µ—Ä–∂–∫–∏) –ø–æ –ø—Ä–∏–æ—Ä–∏—Ç–µ—Ç—É: **low / medium / high**.

---

## 1. –î–∞—Ç–∞—Å–µ—Ç

**–ò—Å—Ç–æ—á–Ω–∏–∫:** [Customer Support Tickets Dataset](https://www.kaggle.com/datasets/tobiasbueck/multilingual-customer-support-tickets)  

**–•–∞—Ä–∞–∫—Ç–µ—Ä–∏—Å—Ç–∏–∫–∏:**
- –†–∞–∑–º–µ—Ä: ~28k –∑–∞–ø–∏—Å–µ–π
- –ü–æ–ª—è: `subject`, `body`, `priority`, `language`
- –ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–æ —Ç–æ–ª—å–∫–æ: **–∞–Ω–≥–ª–∏–π—Å–∫–∏–µ —Ç–µ–∫—Å—Ç—ã**
- –ü–æ—Å–ª–µ –æ–±—ä–µ–¥–∏–Ω–µ–Ω–∏—è `subject + body` –ø–æ–ª—É—á–∏–ª–∏ –ø–æ–ª–µ `text_final`

**–ö–∞—á–µ—Å—Ç–≤–æ –¥–∞–Ω–Ω—ã—Ö:**
- –î–æ–ª—è —à—É–º–Ω—ã—Ö –∑–∞–ø–∏—Å–µ–π (–∫–æ—Ä–æ—Ç–∫–∏–µ/–ø—É—Å—Ç—ã–µ): ~5-7%
- –ë—ã–ª–∏ —É–¥–∞–ª–µ–Ω—ã –Ω–µ–∞–Ω–≥–ª–∏–π—Å–∫–∏–µ –∑–∞–ø–∏—Å–∏
- –¢–µ–∫—Å—Ç—ã –Ω–æ—Ä–º–∞–ª–∏–∑–æ–≤–∞–Ω—ã: –Ω–∏–∂–Ω–∏–π —Ä–µ–≥–∏—Å—Ç—Ä, —É–¥–∞–ª–µ–Ω–∏–µ –ø—É–Ω–∫—Ç—É–∞—Ü–∏–∏, —Ç–æ–∫–µ–Ω–∏–∑–∞—Ü–∏—è, –ª–µ–º–º–∞—Ç–∏–∑–∞—Ü–∏—è (spaCy), —É–¥–∞–ª–µ–Ω–∏–µ —Å—Ç–æ–ø-—Å–ª–æ–≤ (NLTK).

---

## 2. –ü—Ä–µ–¥–æ–±—Ä–∞–±–æ—Ç–∫–∞ –¥–∞–Ω–Ω—ã—Ö

–®–∞–≥–∏:
1. –û—á–∏—Å—Ç–∫–∞ —Ç–µ–∫—Å—Ç–∞ (—Ä–µ–≥—É–ª—è—Ä–Ω—ã–µ –≤—ã—Ä–∞–∂–µ–Ω–∏—è, –Ω–∏–∂–Ω–∏–π —Ä–µ–≥–∏—Å—Ç—Ä)
2. –õ–µ–º–º–∞—Ç–∏–∑–∞—Ü–∏—è (spaCy, `en_core_web_sm`)
3. –£–¥–∞–ª–µ–Ω–∏–µ —Å—Ç–æ–ø-—Å–ª–æ–≤ (NLTK stopwords)
4. –û–±—ä–µ–¥–∏–Ω–µ–Ω–∏–µ –ø–æ–ª–µ–π: `text_final = subject_final + " " + body_final`
5. –†–∞–∑–¥–µ–ª–µ–Ω–∏–µ train/test (80/20)

---

## 3. –ú–µ—Ç–æ–¥—ã –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏

–ë—ã–ª–∏ –ø—Ä–æ—Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω—ã —Å–ª–µ–¥—É—é—â–∏–µ –º–æ–¥–µ–ª–∏:

| # | –ú–æ–¥–µ–ª—å              | –í–µ–∫—Ç–æ—Ä–∏–∑–∞—Ü–∏—è            | Accuracy | Precision | Recall | F1    | Vocab Size |
|---|----------------------|-------------------------|----------|-----------|--------|-------|------------|
| 0 | **SVM**             | TF-IDF (1-4gram)        | **0.7769** | 0.7799    | 0.7769 | 0.7757 | 525144 |
| 1 | **SVM**             | BoW (1-3gram)           | 0.7653   | 0.7692    | 0.7653 | 0.7638 | 525144 |
| 2 | Logistic Regression | BoW (1-4gram)           | 0.7497   | 0.7515    | 0.7497 | 0.7483 | 525144 |
| 3 | Logistic Regression | BoW (1-3gram)           | 0.7442   | 0.7451    | 0.7442 | 0.7430 | 261461 |
| 4 | fastText            | fastText embeddings     | 0.7399   | 0.7432    | 0.7399 | 0.7384 | 3496 |
| 5 | Logistic Regression | BoW (1-2gram)           | 0.7130   | 0.7124    | 0.7130 | 0.7120 | 78144 |
| ‚Ä¶ | ‚Ä¶                   | ‚Ä¶                       | ‚Ä¶        | ‚Ä¶         | ‚Ä¶      | ‚Ä¶     | ‚Ä¶ |

---

## 4. –ê–Ω–∞–ª–∏–∑ –æ—à–∏–±–æ–∫

- –ù–∞–∏–ª—É—á—à–∏–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –ø–æ–∫–∞–∑–∞–ª **SVM + TF-IDF (1‚Äì4 ngram)**: accuracy ‚âà 0.78  
- –ù–∞–∏—Ö—É–¥—à–∏–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã —É **Naive Bayes** –∏ Logistic Regression —Å unigram (~0.48‚Äì0.53)  
- –ö–ª–∞—Å—Å **low** –ø—É—Ç–∞–µ—Ç—Å—è —á–∞—â–µ –≤—Å–µ–≥–æ ‚Äî –º–æ–¥–µ–ª—å —Å–∫–ª–æ–Ω–Ω–∞ –æ—Ç–Ω–æ—Å–∏—Ç—å –µ–≥–æ –∫ medium  
- –û—à–∏–±–∫–∏ –Ω–∞ –∫–æ—Ä–æ—Ç–∫–∏—Ö —Å–æ–æ–±—â–µ–Ω–∏—è—Ö (‚Äúhelp asap‚Äù, ‚Äúplease fix bug‚Äù)

---

## 5. –í—ã–≤–æ–¥—ã

- –ö–ª–∞—Å—Å–∏—á–µ—Å–∫–∏–µ ML-–º–æ–¥–µ–ª–∏ (SVM, Logistic Regression) –ø–æ–∫–∞–∑–∞–ª–∏ —Ö–æ—Ä–æ—à–∏–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã (–¥–æ 77‚Äì78%).  
- fastText –Ω–µ–º–Ω–æ–≥–æ —É—Å—Ç—É–ø–∞–µ—Ç (74%), –Ω–æ –º–æ–∂–µ—Ç –±—ã—Ç—å —É–ª—É—á—à–µ–Ω —Å –ø–æ–¥–±–æ—Ä–æ–º –≥–∏–ø–µ—Ä–ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤ –∏ –±–∞–ª–∞–Ω—Å–∏—Ä–æ–≤–∫–æ–π –∫–ª–∞—Å—Å–æ–≤.  
- –î–ª—è –¥–æ—Å—Ç–∏–∂–µ–Ω–∏—è —Ü–µ–ª–µ–≤–æ–π —Ç–æ—á–Ω–æ—Å—Ç–∏ ‚â• 90 % —Ç—Ä–µ–±—É–µ—Ç—Å—è:  
  - –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å **–Ω–µ–π—Ä–æ—Å–µ—Ç–∏ (RNN, CNN, BiLSTM+Attention)**  (–≤ –ø—Ä–æ—Ü–µ—Å—Å–µ, –¥–æ–ª–æ –æ–±—É—á–∞—é—Ç—Å—è)
  - –±–∞–ª–∞–Ω—Å–∏—Ä–æ–≤–∞—Ç—å –∫–ª–∞—Å—Å—ã (`class_weight`, oversampling)  
  - –ø–æ—Å—Ç—Ä–æ–∏—Ç—å **–∞–Ω—Å–∞–º–±–ª—å** –∏–∑ –ª—É—á—à–∏—Ö –º–æ–¥–µ–ª–µ–π.

---

## 6. –°—Å—ã–ª–∫–∏

- üìì [Colab Notebook](https://colab.research.google.com/drive/1_2r0ZeOn719VTBOXAnDvPN7SBUjMeXlg?usp=sharing)  
