import os
import requests
from pydub import AudioSegment
import telebot
import whisper
import librosa
import noisereduce as nr
import soundfile as sf
import numpy as np
from scipy.signal import butter, filtfilt

from telegram_bot.config import BOT_TOKEN
from text_classifier.inference_model import predict_priority  # üß† –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ç–æ—Ä





# === –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è ===
bot = telebot.TeleBot(BOT_TOKEN)
model = whisper.load_model("small.en")
os.makedirs("data", exist_ok=True)

# === —à—É–º–æ–ø–æ–¥–∞–≤–ª–µ–Ω–∏–µ –∏ —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏—è ===
def denoise_and_filter(wav_path, out_path):
    """–£–¥–∞–ª—è–µ—Ç —à—É–º—ã –∏ –ª–∏—à–Ω–∏–µ —á–∞—Å—Ç–æ—Ç—ã –∏–∑ –∞—É–¥–∏–æ"""
    y, sr = librosa.load(wav_path, sr=16000)
    print(f"üîä Loaded {wav_path}, duration {len(y)/sr:.2f}s")

    # 1Ô∏è‚É£ spectral gating
    noise_len = int(0.5 * sr)
    noise_clip = y[:noise_len] if len(y) > noise_len else y
    y_nr = nr.reduce_noise(y=y, y_noise=noise_clip, sr=sr)

    # 2Ô∏è‚É£ band-pass 80‚Äì7000 Hz
    def butter_bandpass(lowcut, highcut, fs, order=5):
        nyq = 0.5 * fs
        b, a = butter(order, [lowcut/nyq, highcut/nyq], btype='band')
        return b, a

    b, a = butter_bandpass(80, 7000, sr, order=5)
    y_bp = filtfilt(b, a, y_nr)

    sf.write(out_path, y_bp, sr)
    print(f"‚úÖ Cleaned audio saved to {out_path}")
    return out_path


# === –∫–æ–º–∞–Ω–¥—ã ===
@bot.message_handler(commands=['start'])
def send_welcome(message):
    bot.reply_to(
        message,
        "üëã Hi! Send me a *voice message* in English ‚Äî I'll clean it, transcribe it, classify it by priority, and send the result back.",
        parse_mode="Markdown"
    )


# === –æ–±—Ä–∞–±–æ—Ç–∫–∞ –≥–æ–ª–æ—Å–æ–≤—ã—Ö —Å–æ–æ–±—â–µ–Ω–∏–π ===
@bot.message_handler(content_types=['voice'])
def handle_voice(message):
    try:
        print("üéß Voice message received...")

        # === 1Ô∏è‚É£ –°–∫–∞—á–∏–≤–∞–µ–º .ogg ===
        file_info = bot.get_file(message.voice.file_id)
        file_path = file_info.file_path
        file_url = f"https://api.telegram.org/file/bot{BOT_TOKEN}/{file_path}"

        ogg_path = "data/input.ogg"
        wav_path = "data/input.wav"
        clean_path = "data/cleaned.wav"

        r = requests.get(file_url)
        with open(ogg_path, "wb") as f:
            f.write(r.content)
        print("‚úÖ File downloaded")

        # === 2Ô∏è‚É£ –ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ–º OGG ‚Üí WAV ===
        audio = AudioSegment.from_file(ogg_path, format="ogg")
        audio.export(wav_path, format="wav")
        print("üîÑ Converted to WAV")

        # === 3Ô∏è‚É£ –ü—Ä–µ–¥–æ–±—Ä–∞–±–æ—Ç–∫–∞ ===
        denoise_and_filter(wav_path, clean_path)

        # === 4Ô∏è‚É£ –†–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏–µ —Ä–µ—á–∏ (Whisper) ===
        result = model.transcribe(clean_path)
        text = result.get("text", "").strip()
        print("üß† Recognized text:", text)

        if not text:
            bot.reply_to(message, "‚ö†Ô∏è Couldn‚Äôt recognize any speech.")
            return

        # === 5Ô∏è‚É£ –ö–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏—è –ø—Ä–∏–æ—Ä–∏—Ç–µ—Ç–∞ ===
        priority = predict_priority(text).lower()

        emoji = {
            "low": "üü¢",
            "medium": "üü°",
            "high": "üî¥",
            "unknown": "‚ö™Ô∏è"
        }.get(priority, "‚ö™Ô∏è")

        print(f"üéØ Predicted priority: {priority.upper()}")

        # === 6Ô∏è‚É£ –û—Ç–≤–µ—Ç –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—é ===
        reply = (
            f"üó£Ô∏è *Recognized text:*\n{text}\n\n"
            f"{emoji} *Predicted priority:* {priority.upper()}"
        )
        bot.reply_to(message, reply, parse_mode="Markdown")

    except Exception as e:
        print("‚ùå Error:", e)
        bot.reply_to(message, f"‚ö†Ô∏è Error while processing audio: {e}")


print("ü§ñ Bot is running with noise reduction + Whisper + SVM classification...")
bot.infinity_polling()